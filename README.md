Ocean_YOLO
<h1>Code Documentation: Object Detection with Toxicity Level</h1>
General Description
This program uses the YOLO library to detect objects in real-time from the computer's camera. The system provides information about the detected objects, including description, use, and an assessment of their "destructive power." The application also displays a bar graph showing the quantity of each detected object and calculates an overall toxicity level based on the objects.

<h2>Dependencies</h2> <b>tkinter:</b> For creating the graphical interface.<br> <b>ultralytics:</b> For object detection using the YOLO model.<br> <b>cv2 (OpenCV):</b> For video capture and image manipulation.<br> <b>threading:</b> To run tasks in parallel.<br> <b>time:</b> To control time intervals.<br> <b>pyttsx3:</b> For text-to-speech synthesis.<br> <b>PIL (Pillow):</b> For image manipulation.<br> <b>requests:</b> For API calls to Wikidata.<br> <b>geocoder:</b> To obtain the user's geographical location.<br> <b>matplotlib:</b> To generate graphs.<br> <h2>Code Structure</h2> <h2>Initialization</h2> The text-to-speech engine is initialized to allow the narration of detected objects. Dictionaries and variables are defined to store information about detected objects and their "destructive powers."<br> <b>TIME_LIMIT_RECOUNT</b> controls how often an object can be recounted.<br> <h3>Main Functions</h3> <b>query_wikidata(object_name):</b><br> Queries the Wikidata API to obtain information about a detected object.<br> Returns the description and use of the object.<br> <b>narrate(text):</b><br> <b>Uses the text-to-speech engine to narrate the provided text.</b><br> <b>calculate_toxicity():</b><br> <b>Calculates the total toxicity level based on the detected objects and their destructive power.</b><br> <b>display_graph():</b><br> <b>Generates and displays a bar graph with the quantity of each detected object.</b><br> <b>Updates the Tkinter interface with the graph.</b><br> <b>get_geolocation():</b><br> Obtains the user's geographical location using their IP address.<br> <b>update_info():</b><br> Updates the user interface with information about detected objects, including description, use, quantity, and total toxicity level.<br> <b>Displays the updated graph.</b><br> <b>detect():</b><br> Captures video from the camera, processes frames, and detects objects using the YOLO model.<br> Updates information in the interface and narrates detected objects.<br> <b>pause_detection():</b><br> Pauses or resumes object detection based on the current state.<br> <b>clear_detections():</b><br> Clears all object detections and updates the interface.<br>
<b>Tkinter Interface Setup</b><br> The main window is set up with three frames:<br> <b>frame_video:</b> To display the camera video.<br> <b>frame_info:</b> To show information about detected objects and control buttons.<br> <b>frame_graph:</b> To display graphs and error messages.<br> Control buttons to pause detection and clear detections are created.<br>

<h1>First Execution</h1> The YOLO model is loaded from a pre-trained file (yolov8n.pt).<br> Detection is started in a separate thread to ensure the interface remains responsive.<br> The main loop of the Tkinter interface is initiated.<br> <h1>Final Considerations</h1> This application is a demonstration of the use of computer vision and graphical interface to monitor and inform about environmental pollution. The combination of object detection and toxicity analysis provides a useful tool for raising awareness and educating about the impact of waste on the environment.
